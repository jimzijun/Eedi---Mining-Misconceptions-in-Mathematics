{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c eedi-mining-misconceptions-in-mathematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "misconception_df = pd.read_csv('dataset/misconception_mapping.csv')\n",
    "sample_submission_df = pd.read_csv('dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(n=20, random_state=42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting 10% for evaluation, 90% for training\n",
    "train_df, eval_df = train_test_split(train_df, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_dataframe(df, misconception_df=None, train_flag=False):\n",
    "    # List of options\n",
    "    options = ['A', 'B', 'C', 'D']\n",
    "\n",
    "    # List of columns to keep\n",
    "    id_vars = ['QuestionId', 'QuestionText', 'ConstructId', 'ConstructName', 'SubjectId', 'SubjectName', 'CorrectAnswer']\n",
    "\n",
    "    # Initialize an empty list to collect data\n",
    "    data_list = []\n",
    "\n",
    "    # Loop over each option to collect data\n",
    "    for option in options:\n",
    "        answer_col = f'Answer{option}Text'\n",
    "        misconception_col = f'Misconception{option}Id'\n",
    "        \n",
    "        # Check if the misconception column exists\n",
    "        if misconception_col in df.columns:\n",
    "            temp_df = df[id_vars + [misconception_col, answer_col]].copy()\n",
    "            temp_df.rename(columns={\n",
    "                misconception_col: 'MisconceptionId',\n",
    "                answer_col: 'AnswerText'\n",
    "            }, inplace=True)\n",
    "        else:\n",
    "            # Only include the answer column if misconception column doesn't exist\n",
    "            temp_df = df[id_vars + [answer_col]].copy()\n",
    "            temp_df['MisconceptionId'] = None  # Assign None to MisconceptionId\n",
    "            temp_df.rename(columns={\n",
    "                answer_col: 'AnswerText'\n",
    "            }, inplace=True)\n",
    "        \n",
    "        temp_df['Option'] = option\n",
    "        data_list.append(temp_df)\n",
    "\n",
    "    # Concatenate all the data into a single DataFrame\n",
    "    df_combined = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "    # Exclude the rows where the option matches the correct answer\n",
    "    df_combined = df_combined[df_combined['Option'] != df_combined['CorrectAnswer']]\n",
    "\n",
    "    # If train_flag is True, merge with 'misconception_df' on 'MisconceptionId'\n",
    "    if train_flag and misconception_df is not None and 'MisconceptionId' in df_combined.columns:\n",
    "        df_combined = df_combined.merge(misconception_df, on='MisconceptionId', how='left')\n",
    "        \n",
    "        # Drop rows with missing 'MisconceptionName' (only for training data)\n",
    "        if 'MisconceptionName' in df_combined.columns:\n",
    "            df_combined = df_combined.dropna(subset=['MisconceptionName'])\n",
    "    else:\n",
    "        # For testing data, add a placeholder for 'MisconceptionName'\n",
    "        df_combined['MisconceptionName'] = None\n",
    "\n",
    "    # Sort and reset index if desired\n",
    "    df_combined = df_combined.sort_values([\"QuestionId\", \"Option\"]).reset_index(drop=True)\n",
    "\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_procressed_df = preprocess_dataframe(train_df, misconception_df, train_flag=True)\n",
    "eval_procressed_df = preprocess_dataframe(eval_df, misconception_df, train_flag=True)\n",
    "test_procressed_df = preprocess_dataframe(test_df, misconception_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_row_for_qa_token(row, train_flag=False):\n",
    "    # Replace newlines in all relevant fields\n",
    "    construct_name = row['ConstructName'].replace('\\n', ' ')\n",
    "    subject_name = row['SubjectName'].replace('\\n', ' ')\n",
    "    question_text = row['QuestionText'].replace('\\n', ' ')\n",
    "    answer_text = row['AnswerText'].replace('\\n', ' ')\n",
    "    \n",
    "    # Create a prompt for the question_text\n",
    "    question_prompt = (f\"Given the following context:\\n\"\n",
    "                       f\"Construct: {construct_name}, Subject: {subject_name}.\\n\"\n",
    "                       f\"Question: {question_text}\\n\"\n",
    "                       f\"Answer: {answer_text}\\n\"\n",
    "                       f\"Please predict the misconception.\")\n",
    "\n",
    "    # Set answer_text as the misconception for training\n",
    "    if train_flag and row['MisconceptionName'] is not None:\n",
    "        misconception_name = row['MisconceptionName'].replace('\\n', ' ')\n",
    "    else:\n",
    "        misconception_name = ''\n",
    "\n",
    "    # Return a DataFrame with question_text (prompt) and answer_text (misconception)\n",
    "    return pd.DataFrame({\n",
    "        'question_text': [question_prompt],\n",
    "        'answer_text': [misconception_name] if train_flag else [None]  # Use None during inference\n",
    "    })\n",
    "\n",
    "# Process the entire DataFrame for QA preparation\n",
    "def process_dataframe_for_qa_token(df, train_flag=False):\n",
    "    processed_rows = []\n",
    "    \n",
    "    # Loop through each row in the input DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        processed_row = process_row_for_qa_token(row, train_flag)\n",
    "        processed_rows.append(processed_row)\n",
    "    \n",
    "    # Concatenate the results into a final DataFrame\n",
    "    final_df = pd.concat(processed_rows, ignore_index=True)\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = 'data/train.csv'\n",
    "EVAL_DF = 'data/eval.csv'\n",
    "TEST_DF = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataframe_for_qa_token(train_procressed_df, train_flag=True).to_csv(TRAIN_DF, index=False)\n",
    "process_dataframe_for_qa_token(eval_procressed_df, train_flag=True).to_csv(EVAL_DF, index=False)\n",
    "process_dataframe_for_qa_token(test_procressed_df, train_flag=False).to_csv(TEST_DF, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load your data\n",
    "train_df = pd.read_csv(TRAIN_DF)  # Contains 'question_text' and 'answer_text'\n",
    "eval_df = pd.read_csv(EVAL_DF)    # Optional evaluation data\n",
    "test_df = pd.read_csv(TEST_DF).fillna('')    # Contains 'question_text' only\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "if not eval_df.empty:\n",
    "    eval_dataset = Dataset.from_pandas(eval_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/miniconda3/envs/kaggle/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "\n",
      "\u001b[A/Users/jim/miniconda3/envs/kaggle/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4117: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 902.59 examples/s]\n",
      "\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 642.85 examples/s]\n",
      "\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 1762.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "# Tokenization function\n",
    "def preprocess_function(examples):\n",
    "    inputs = [q for q in examples[\"question_text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    # For training data, add labels\n",
    "    if \"answer_text\" in examples:\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(examples[\"answer_text\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "# Apply the preprocessing\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True, remove_columns=eval_dataset.column_names)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=test_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/miniconda3/envs/kaggle/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\" if not eval_df.empty else \"no\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
